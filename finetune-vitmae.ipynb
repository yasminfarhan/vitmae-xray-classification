{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDhUsYU7G_wK"
      },
      "source": [
        "### Importing relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "317RrqC8Do8A"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install evaluate\n",
        "!pip install transforms\n",
        "\n",
        "!pip install \"ray[tune]\" scipy sklearn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import json\n",
        "import glob \n",
        "import itertools\n",
        "from PIL import Image\n",
        "from transformers import (\n",
        "    AutoImageProcessor, \n",
        "    ViTForImageClassification, \n",
        "    SwinForImageClassification,\n",
        "    TrainingArguments, \n",
        "    Trainer,\n",
        "    ResNetModel,\n",
        "    AutoTokenizer, \n",
        "    BertModel,\n",
        "    BertPreTrainedModel,\n",
        "    DefaultDataCollator,\n",
        "    ViTFeatureExtractor,\n",
        "    ViTMAEForPreTraining,\n",
        "    ViTMAEConfig,\n",
        "    ViTImageProcessor\n",
        ")\n",
        "from tqdm.auto import tqdm\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "import requests\n",
        "from sklearn import datasets\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_predict, train_test_split\n",
        "# import scikitplot as skplt\n",
        "import pandas as pd\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZegSbbnnFx4_"
      },
      "source": [
        "### Training helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ln0GxBEFxpG"
      },
      "outputs": [],
      "source": [
        "# A function to see the size and # of params of a model - taken from class examples\n",
        "def get_model_info(model):\n",
        "    # Compute number of trainable parameters in the model\n",
        "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "    # Compute the size of the model in MB\n",
        "    param_size = 0\n",
        "    for param in model.parameters():\n",
        "        param_size += param.nelement() * param.element_size()\n",
        "    buffer_size = 0\n",
        "    for buffer in model.buffers():\n",
        "        buffer_size += buffer.nelement() * buffer.element_size()\n",
        "        \n",
        "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "    \n",
        "    return num_params, size_all_mb\n",
        "\n",
        "# Data collator - form a batch by using a list of dataset elements as input\n",
        "def collate_fn(examples):\n",
        "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
        "    labels = torch.tensor([example[\"labels\"] for example in examples])\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd9TXZp9D5OP"
      },
      "source": [
        "### Visualizing output from pretrained ViTMAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hk-JBc7EHrT"
      },
      "outputs": [],
      "source": [
        "# from https://github.com/NielsRogge/Transformers-Tutorials/blob/master/ViTMAE/ViT_MAE_visualization_demo.ipynb\n",
        "\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(\"facebook/vit-mae-base\")\n",
        "imagenet_mean = np.array(feature_extractor.image_mean)\n",
        "imagenet_std = np.array(feature_extractor.image_std)\n",
        "\n",
        "def show_image(image, title=''):\n",
        "    # image is [H, W, 3]\n",
        "    assert image.shape[2] == 3\n",
        "    converted_img = torch.clip((image * imagenet_std + imagenet_mean) * 255, 0, 255).int()\n",
        "    plt.imshow(converted_img)\n",
        "    plt.title(title, fontsize=16)\n",
        "    plt.axis('off')\n",
        "    return \n",
        "\n",
        "def visualize_single_image(pixel_values):\n",
        "    x = torch.einsum('nchw->nhwc', pixel_values)\n",
        "    show_image(x[0], \"original\")\n",
        "\n",
        "def visualize(pixel_values, model):\n",
        "    # forward pass\n",
        "    outputs = model(pixel_values)\n",
        "    y = model.unpatchify(outputs.logits)\n",
        "    y = torch.einsum('nchw->nhwc', y).detach().cpu()\n",
        "    \n",
        "    # visualize the mask\n",
        "    mask = outputs.mask.detach()\n",
        "    mask = mask.unsqueeze(-1).repeat(1, 1, model.config.patch_size**2 *3)  # (N, H*W, p*p*3)\n",
        "    mask = model.unpatchify(mask)  # 1 is removing, 0 is keeping\n",
        "    mask = torch.einsum('nchw->nhwc', mask).detach().cpu()\n",
        "    \n",
        "    x = torch.einsum('nchw->nhwc', pixel_values)\n",
        "\n",
        "    # masked image\n",
        "    im_masked = x * (1 - mask)\n",
        "\n",
        "    # MAE reconstruction pasted with visible patches\n",
        "    im_paste = x * (1 - mask) + y * mask\n",
        "\n",
        "    # make the plt figure larger\n",
        "    plt.rcParams['figure.figsize'] = [24, 24]\n",
        "\n",
        "    plt.subplot(1, 4, 1)\n",
        "    show_image(x[0], \"original\")\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    show_image(im_masked[0], \"masked\")\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    show_image(y[0], \"reconstruction\")\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    show_image(im_paste[0], \"reconstruction + visible\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# make random mask reproducible (comment out to make it change)\n",
        "torch.manual_seed(2)\n",
        "\n",
        "model = ViTMAEForPreTraining.from_pretrained(\"facebook/vit-mae-base\")\n",
        "\n",
        "#### Specific image example\n",
        "url = \"https://datasets-server.huggingface.co/assets/keremberke/chest-xray-classification/--/full/train/2/image/image.jpg\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "pixel_values = feature_extractor(image, return_tensors=\"pt\").pixel_values\n",
        "visualize(pixel_values, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset preprocessing"
      ],
      "metadata": {
        "id": "tObxMOFTf0r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cudnn.benchmark = True\n",
        "plt.ion()   # interactive mode\n",
        "nih_dataset = False\n",
        "model_name_or_path = (\n",
        "    \"facebook/vit-mae-base\"\n",
        ")\n",
        "data_dir_name = \"./vit-finetune\"\n",
        "\n",
        "# loading dataset\n",
        "if nih_dataset:\n",
        "  ds = load_dataset(\"alkzar90/NIH-Chest-X-ray-dataset\", name=\"image-classification\")\n",
        "  labels = ds[\"train\"].features[\"labels\"].feature.names #nih dataset\n",
        "  test_ds = \"test\"\n",
        "else:\n",
        "  ds = load_dataset(\"keremberke/chest-xray-classification\", name=\"full\")\n",
        "  labels = ds[\"train\"].features[\"labels\"].names #chest xray dataset\n",
        "  test_ds = \"validation\"\n",
        "ds = ds.with_format(\"torch\")\n",
        "\n",
        "#loading image_processor\n",
        "image_processor = ViTImageProcessor.from_pretrained(model_name_or_path, padding=True) #gives normalize func error\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# defining a custom weighted loss for my imbalanced dataset                                   - see https://huggingface.co/docs/transformers/main_classes/trainer?highlight=trainer#trainer\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss (data biases positive label, weight 0 label more)\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([2.0, 1.0]).to(device))\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "#defining transforms\n",
        "size = (\n",
        "    image_processor.size[\"shortest_edge\"] if \"shortest_edge\" in image_processor.size\n",
        "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
        ")\n",
        "normalize = transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
        "\n",
        "# includes data augmentation\n",
        "train_transforms = transforms.Compose(\n",
        "        [\n",
        "            transforms.RandomResizedCrop(size),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]\n",
        "    )\n",
        "\n",
        "#no data augmentation\n",
        "val_transforms = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(size),\n",
        "            transforms.CenterCrop(size),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]\n",
        "    )\n",
        "\n",
        "def preprocess_train(example_batch):\n",
        "    \"\"\"Apply train_transforms across a batch.\"\"\"\n",
        "    example_batch[\"pixel_values\"] = [\n",
        "        train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
        "    ]\n",
        "    return example_batch\n",
        "\n",
        "def preprocess_val(example_batch):\n",
        "    \"\"\"Apply val_transforms across a batch.\"\"\"\n",
        "    example_batch[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
        "    return example_batch\n",
        "\n",
        "ds['train'].set_transform(preprocess_train)\n",
        "ds['validation'].set_transform(preprocess_val)"
      ],
      "metadata": {
        "id": "q8kj2b3-f3wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter search with Ray Tune"
      ],
      "metadata": {
        "id": "FKxET-wSfStX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ray[tune]\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter, ResultGrid\n",
        "from ray.tune.examples.pbt_transformers.utils import (\n",
        "    download_data,\n",
        "    build_compute_metrics_fn,\n",
        ")\n",
        "from ray.tune.schedulers import PopulationBasedTraining\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import (\n",
        "    AutoConfig\n",
        ")\n",
        "\n",
        "smoke_test = False\n",
        "samples = 20\n",
        "gpus_per_trial = 1\n",
        "\n",
        "task_name = \"rte\"\n",
        "task_data_dir = data_dir_name+\"-\"+task_name\n",
        "num_labels = len(labels)\n",
        "\n",
        "# init config object\n",
        "config = AutoConfig.from_pretrained(\n",
        "    model_name_or_path, num_labels=num_labels, finetuning_task=task_name\n",
        ")\n",
        "\n",
        "# Triggers pre-trained model download to cache\n",
        "ViTForImageClassification.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "# define model initialization function for trainer\n",
        "def model_init():\n",
        "    model = ViTForImageClassification.from_pretrained(\n",
        "        model_name_or_path,\n",
        "        config=config,\n",
        "    )\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "    \n",
        "    # Freeze the entire model:\n",
        "    for p in model.parameters():\n",
        "      p.requires_grad = False\n",
        "    \n",
        "    # Turn back on the classifier weights\n",
        "    for p in model.classifier.parameters():\n",
        "      p.requires_grad=True  \n",
        "\n",
        "    return model\n",
        "\n",
        "# define training arguments\n",
        "training_args = TrainingArguments(\n",
        "  output_dir=task_data_dir,\n",
        "  per_device_train_batch_size=16,\n",
        "  per_device_eval_batch_size=32,\n",
        "  evaluation_strategy=\"epoch\", \n",
        "  num_train_epochs=4,\n",
        "  save_steps=100,\n",
        "  eval_steps=100,\n",
        "  logging_steps=10,\n",
        "  learning_rate=1e-5,\n",
        "  save_total_limit=2,\n",
        "  remove_unused_columns=False,\n",
        "  push_to_hub=False,\n",
        "  # report_to='tensorboard',\n",
        "  load_best_model_at_end=True,\n",
        "  do_train=True,\n",
        "  do_eval=True,\n",
        "  # max_steps=-1,\n",
        "  weight_decay=0.1,\n",
        "  logging_dir=\"./logs\",\n",
        "  skip_memory_metrics=True,\n",
        "  report_to=\"none\",\n",
        "\n",
        "  #from class\n",
        "  save_strategy=\"epoch\",\n",
        "  lr_scheduler_type=\"cosine\",\n",
        "  dataloader_num_workers=0,\n",
        ")\n",
        "\n",
        "# create tune config object\n",
        "tune_config = {\n",
        "    \"per_device_train_batch_size\": 16,\n",
        "    \"per_device_eval_batch_size\": 16,\n",
        "    \"num_train_epochs\": tune.choice([2, 3, 4]),\n",
        "    \"max_steps\": 1 if smoke_test else 200,  # Used for smoke test.\n",
        "}\n",
        "\n",
        "# initialize scheduler with args\n",
        "scheduler = PopulationBasedTraining(\n",
        "    time_attr=\"training_iteration\",\n",
        "    metric=\"eval_acc\",\n",
        "    mode=\"max\",\n",
        "    perturbation_interval=1,\n",
        "    hyperparam_mutations={\n",
        "        \"weight_decay\": tune.uniform(0.0, 0.3),\n",
        "        \"learning_rate\": tune.uniform(1e-5, 5e-5),\n",
        "        \"per_device_train_batch_size\": tune.choice([8, 16, 32]),\n",
        "        \"per_device_eval_batch_size\": tune.choice([8, 16, 32]),\n",
        "        \"lr_scheduler_type\": tune.choice([\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant_with_warmup\"]),\n",
        "    },\n",
        ")\n",
        "\n",
        "# initialize report with args, define what info what will be reported\n",
        "reporter = CLIReporter(\n",
        "    parameter_columns={\n",
        "        \"weight_decay\": \"w_decay\",\n",
        "        \"learning_rate\": \"lr\",\n",
        "        \"per_device_train_batch_size\": \"train_bs/gpu\",\n",
        "        \"num_train_epochs\": \"num_epochs\",\n",
        "        \"lr_scheduler_type\": \"lr_scheduler\",\n",
        "    },\n",
        "    metric_columns=[\"eval_acc\", \"eval_loss\", \"epoch\", \"training_iteration\"],\n",
        ")\n",
        "\n",
        "# Create the trainer\n",
        "trainer = Trainer(\n",
        "    model=None,\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    data_collator=collate_fn,\n",
        "    compute_metrics=build_compute_metrics_fn(task_name),\n",
        "    train_dataset=ds[\"train\"],\n",
        "    eval_dataset=ds[\"validation\"],\n",
        "    tokenizer=image_processor,\n",
        ")\n",
        "\n",
        "# launch hyperparameter search\n",
        "trainer.hyperparameter_search(\n",
        "    hp_space=lambda _: tune_config,\n",
        "    backend=\"ray\",\n",
        "    n_trials=samples,\n",
        "    resources_per_trial={\"cpu\": 1, \"gpu\": gpus_per_trial},\n",
        "    scheduler=scheduler,\n",
        "    keep_checkpoints_num=1,\n",
        "    checkpoint_score_attr=\"training_iteration\",\n",
        "    stop={\"training_iteration\": 1} if smoke_test else None,\n",
        "    progress_reporter=reporter,\n",
        "    local_dir=\"./ray_results/\",\n",
        "    name=\"tune_transformer_pbt\",\n",
        "    log_to_file=True,\n",
        ")"
      ],
      "metadata": {
        "id": "ei2W3EphfRol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vCXRpc9EMAX"
      },
      "source": [
        "### Fine-tuning on custom dataset using best hyperparameter results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rttp9LYcQhY"
      },
      "outputs": [],
      "source": [
        "model = ViTForImageClassification.from_pretrained(\n",
        "    \"facebook/vit-mae-base\",\n",
        "    num_labels=len(labels),\n",
        "    id2label={str(i): c for i, c in enumerate(labels)},\n",
        "    label2id={c: str(i) for i, c in enumerate(labels)},\n",
        "    ignore_mismatched_sizes=True,\n",
        "    # problem_type=\"multi_label_classification\", #for nih dataset\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "# Print model info\n",
        "num_params, size_all_mb = get_model_info(model)\n",
        "\n",
        "# Freeze the entire model:\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "    \n",
        "# Turn back on the classifier weights\n",
        "for p in model.classifier.parameters():\n",
        "    p.requires_grad=True\n",
        "\n",
        "# Setup the training arguments\n",
        "output_dir = \"./finetune_vit\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=3,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,\n",
        "    remove_unused_columns=False, #we need the unused features ('image' in particular) in order to create 'pixel_values'\n",
        "    push_to_hub=False,\n",
        "    load_best_model_at_end=True,\n",
        "    dataloader_num_workers=0,  \n",
        "#     gradient_accumulation_steps=8,\n",
        ")\n",
        "\n",
        "# Compute absolute learning rate\n",
        "base_learning_rate = 1e-3\n",
        "total_train_batch_size = (\n",
        "    training_args.train_batch_size * training_args.gradient_accumulation_steps * training_args.world_size\n",
        ")\n",
        "\n",
        "training_args.learning_rate = base_learning_rate * total_train_batch_size / 256\n",
        "print(\"Set learning rate to:\", training_args.learning_rate)\n",
        "\n",
        "# Setup a function to compute accuracy metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    metric1 = evaluate.load(\"precision\")\n",
        "    metric2 = evaluate.load(\"recall\")\n",
        "    metric3 = evaluate.load(\"accuracy\")\n",
        "    metric4 = evaluate.load(\"f1\")\n",
        "\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    precision = metric1.compute(predictions=predictions, references=labels)[\"precision\"]\n",
        "    recall = metric2.compute(predictions=predictions, references=labels)[\"recall\"]\n",
        "    accuracy = metric3.compute(predictions=np.argmax(eval_pred.predictions, axis=1), references=eval_pred.label_ids)[\"accuracy\"]\n",
        "    f1_score = metric4.compute(predictions=predictions, references=labels)[\"f1\"]\n",
        "\n",
        "    return {\"precision\": precision, \"recall\": recall, \"accuracy\": accuracy, \"f1_score\": f1_score}\n",
        "\n",
        "# Create the trainer\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=ds['train'],\n",
        "    eval_dataset=ds[test_ds], \n",
        "    tokenizer=image_processor,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        "    # data_collator=DefaultDataCollator(),\n",
        ")\n",
        "\n",
        "# Train\n",
        "train_results = trainer.train()\n",
        "trainer.save_model()\n",
        "trainer.log_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_state()\n",
        "\n",
        "# Inference\n",
        "predictions = trainer.predict(ds[test_ds])\n",
        "\n",
        "# Evaluation\n",
        "metrics = trainer.evaluate(ds[test_ds])\n",
        "trainer.log_metrics(\"eval\", metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference & Visualization"
      ],
      "metadata": {
        "id": "G9sh5sExNKvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install scikit-plot==0.3.7\n",
        "from transformers import pipeline\n",
        "from sklearn import datasets, metrics\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_predict, train_test_split\n",
        "import scikitplot as skplt\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from transformers.pipelines.pt_utils import KeyDataset\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "ds = load_dataset(\"keremberke/chest-xray-classification\", name=\"full\")\n",
        "\n",
        "# Inference using the model on unseen test data\n",
        "ds['test'].set_transform(preprocess_val)\n",
        "predictions = trainer.predict(ds['test'])\n",
        "\n",
        "# metrics\n",
        "print(\"Accuracy:\", predictions.metrics[\"test_accuracy\"])\n",
        "print(\"Precision:\", predictions.metrics[\"test_precision\"])\n",
        "print(\"Recall:\", predictions.metrics[\"test_recall\"])\n",
        "print(\"F1-Score:\", predictions.metrics[\"test_f1_score\"])\n",
        "\n",
        "# Probability scores\n",
        "y_probs = torch.nn.functional.softmax(torch.Tensor(predictions[0]), dim=-1) #retrieving probabilities that would be returned by self.classifier\n",
        "\n",
        "# Ground truth\n",
        "y_test = ds['test'].with_format(\"torch\")['labels']\n",
        "\n",
        "# Probability of the class with the greater label & predicted label ids\n",
        "y_max_probs, y_preds = torch.max(y_probs,1)\n",
        "\n",
        "##### Visualization\n",
        "plt.rc('font', size=12) # controls default text sizes\n",
        "\n",
        "print(\"roc_auc_score:\", metrics.roc_auc_score(y_test, y_max_probs))\n",
        "\n",
        "#visualizing class distribution of training data\n",
        "plt.bar([\"NORMAL\", \"PNEUMONIA\"], [len(ds['train']['labels'])-sum(ds['train']['labels']), sum(ds['train']['labels'])])\n",
        "plt.title(\"Class distribution of training data\")\n",
        "\n",
        "# plotting ROC curve\n",
        "skplt.metrics.plot_roc(y_test, y_probs, title = 'ROC Plot for Chest X-Ray dataset')\n",
        "plt.show()\n",
        "\n",
        "#plotting precision, recall across classification thresholds\n",
        "skplt.metrics.plot_precision_recall(y_test, y_probs, title = 'PR Curve for Chest X-Ray dataset')\n",
        "plt.show()\n",
        "\n",
        "#plotting cumulative gain\n",
        "skplt.metrics.plot_cumulative_gain(y_test, y_probs, title = 'Cumulative Gains Chart for Chest X-Ray dataset')\n",
        "plt.show()\n",
        "\n",
        "# plotting confusion matrix\n",
        "# skplt.metrics.plot_confusion_matrix(y_test, y_preds, normalize=False, title = 'Normalized Confusion Matrix for Chest X-Ray dataset')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "hI_pIWSIG6qv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "CDhUsYU7G_wK",
        "ZegSbbnnFx4_",
        "wd9TXZp9D5OP",
        "tObxMOFTf0r1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}